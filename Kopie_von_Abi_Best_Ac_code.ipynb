{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von Abi_Best_Ac_code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vkaJup57POCU",
        "rLiBgJB_Rsg3",
        "TxIlB9TLtoQG",
        "V1tmsWfkZEH0"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/98bao/Migros/blob/main/Kopie_von_Abi_Best_Ac_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrzyRYGbESJu"
      },
      "source": [
        "#DMML2020 - Project\n",
        "![mod-fr-logo.png](data:image/png;base64,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)\n",
        "##Classification problem\n",
        "In this project we analyze the data to know if a tweet is about a real disaster (target = 1) or not (target = 0).\n",
        "\n",
        "\n",
        "In this first iteration we just fit the training data in the Logistic regression and observe the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9MSBRePXde"
      },
      "source": [
        "#Report üìã\n",
        "  1) At first we submitted a simple logistic regression without data cleaning which gave us a satisfying accuracy of **0.805** on AICrowd\n",
        "  \n",
        "  2) We cleaned the text by deleting unecessary elements, then applied a logistic regression with cross validation (LRCV). Although the model built on the train data is pretty good, the accuracy on AICrowd got lower: **0.797**\n",
        "\n",
        "  3) We used the Random Forest Classifier (RFC) and its model accuracy seemed very promising (0.97 for the train data) however, whilst submitting to AICrowd we got only a result of **0.77**. It seems like we are missing an important point as our accuracy keeps getting lower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4NAEzRJulWP"
      },
      "source": [
        "#Importing useful tools üß∞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uznVfXhudk5"
      },
      "source": [
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD-6gZ29AwoF"
      },
      "source": [
        "#clear output\n",
        "%%capture \n",
        "# Install and update spaCy\n",
        "!pip install -U spacy\n",
        "\n",
        "!python -m spacy download en\n",
        "import spacy\n",
        "from spacy import displacy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83nQQMoOxwMw",
        "outputId": "e57113a2-d67a-41f7-b3c2-2b508b25e732"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL8FAIy_D97-"
      },
      "source": [
        "#clear output\n",
        "%%capture \n",
        "\n",
        "#Importing useful extensions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim.models import Doc2Vec"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs646BIHutyE"
      },
      "source": [
        "#Importing the project dataframes in the notebook üìö\n",
        "In the following cells, we import some raw dataframes that we are going to use for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SI2JEC6p6MW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4a98a09e-926d-4211-af77-985b6c286917"
      },
      "source": [
        "#Reading the dataframe to build our model\n",
        "df_train = pd.read_csv(\"https://raw.githubusercontent.com/98bao/Migros/main/data/training_data.csv\")\n",
        "df_train.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3738</td>\n",
              "      <td>destroyed</td>\n",
              "      <td>USA</td>\n",
              "      <td>Black Eye 9: A space battle occurred at Star O...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>853</td>\n",
              "      <td>bioterror</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#world FedEx no longer to transport bioterror ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10540</td>\n",
              "      <td>windstorm</td>\n",
              "      <td>Palm Beach County, FL</td>\n",
              "      <td>Reality Training: Train falls off elevated tra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5988</td>\n",
              "      <td>hazardous</td>\n",
              "      <td>USA</td>\n",
              "      <td>#Taiwan Grace: expect that large rocks trees m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6328</td>\n",
              "      <td>hostage</td>\n",
              "      <td>Australia</td>\n",
              "      <td>New ISIS Video: ISIS Threatens to Behead Croat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id    keyword  ...                                               text target\n",
              "0   3738  destroyed  ...  Black Eye 9: A space battle occurred at Star O...      0\n",
              "1    853  bioterror  ...  #world FedEx no longer to transport bioterror ...      0\n",
              "2  10540  windstorm  ...  Reality Training: Train falls off elevated tra...      1\n",
              "3   5988  hazardous  ...  #Taiwan Grace: expect that large rocks trees m...      1\n",
              "4   6328    hostage  ...  New ISIS Video: ISIS Threatens to Behead Croat...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKe5CpOADsUu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3dfffa90-6082-4a05-c533-450f392a51fe"
      },
      "source": [
        "#Reading dataframe which is going to be tested\n",
        "df_test = pd.read_csv(\"https://raw.githubusercontent.com/98bao/Migros/main/data/test_data.csv\")\n",
        "df_test.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9972</td>\n",
              "      <td>tsunami</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Crptotech tsunami and banks.\\n http://t.co/KHz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9865</td>\n",
              "      <td>traumatised</td>\n",
              "      <td>Portsmouth, UK</td>\n",
              "      <td>I'm that traumatised that I can't even spell p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1937</td>\n",
              "      <td>burning%20buildings</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@foxnewsvideo @AIIAmericanGirI @ANHQDC So ... ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3560</td>\n",
              "      <td>desolate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Me watching Law &amp;amp; Order (IB: @sauldale305)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2731</td>\n",
              "      <td>crushed</td>\n",
              "      <td>bahstun/porta reeko</td>\n",
              "      <td>Papi absolutely crushed that ball</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ...                                               text\n",
              "0  9972  ...  Crptotech tsunami and banks.\\n http://t.co/KHz...\n",
              "1  9865  ...  I'm that traumatised that I can't even spell p...\n",
              "2  1937  ...  @foxnewsvideo @AIIAmericanGirI @ANHQDC So ... ...\n",
              "3  3560  ...  Me watching Law &amp; Order (IB: @sauldale305)...\n",
              "4  2731  ...                  Papi absolutely crushed that ball\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPXIETd0XWep"
      },
      "source": [
        "#Reading the sample submission\n",
        "sample_submission = pd.read_csv(\"https://raw.githubusercontent.com/98bao/Migros/main/data/sample_submission.csv\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VsqXyB2Rt_R"
      },
      "source": [
        "#Exploratory data analysis üïµÔ∏è\n",
        "\n",
        "1.   Base rate\n",
        "2.   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQNMU60cLMIN"
      },
      "source": [
        "####1. Base rate\n",
        "This indicate how often the most common value appears in the dataframe. We have to obtain an accuracy that is superior to the base rate to say that our classifier is well made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwbEL3b8GFtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1989bdff-ac94-4f20-a73a-7f1ce4097a22"
      },
      "source": [
        "#Base rate of the train df\n",
        "df_train['target'].value_counts() /len(df_train) \n",
        "\n",
        "#The base rate of this dataframe is 0.572"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.571936\n",
              "1    0.428064\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MrFFGBsTTgn",
        "outputId": "211abaf9-bd99-4153-9af4-1a4fff5ad5f3"
      },
      "source": [
        "#Are there null values ?\n",
        "print(df_train.text.isnull().sum())\n",
        "print(df_train.keyword.isnull().sum())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr07BaekKej2"
      },
      "source": [
        "#Building the tokenizer ü§ñ\n",
        "In the following part, we create our tokenizer which will be used to analyze the text column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP_WL2YrJ3nF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7eab4bf1-2494-4f0c-be01-257058fd16ff"
      },
      "source": [
        "#Create Tokenizer\n",
        "\n",
        "#Stopwords\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "#Punctuation\n",
        "punctuations = string.punctuation\n",
        "\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "#Tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    mytokens = sp(sentence)\n",
        "\n",
        "    # Lemmatize each token and convert each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]  \n",
        "    # Remove stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "    \n",
        "    ps = PorterStemmer()\n",
        "    stemmed_words = [ps.stem(w) for w in mytokens]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemma_words = [lemmatizer.lemmatize(w, pos='a') for w in stemmed_words]\n",
        "    # Return preprocessed list of tokens\n",
        "    return lemma_words\n",
        "\n",
        "#demo\n",
        "review = df_train[\"text\"].sample()\n",
        "review.values[0]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'@FoxNews He still has his beard - has he been visited by any1 while in prison? If he keeps that hideous beard electrocute him! \\n#UglyPeople'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3nifglrKSf_"
      },
      "source": [
        "#TF-IDF feature vector\n",
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6MnoVaZLu3O"
      },
      "source": [
        "#Logistic regression and pipeline\n",
        "\n",
        "Our first iteration of the model: *No treatement of the dataframe*, just fitted in a logistic regression to see the result. We submitted this first try on AICrowd to check the accuracy of an uncleaned database.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq2BiGZiHYQc"
      },
      "source": [
        "#Setting up the train test split\n",
        "\n",
        "#First for the training data\n",
        "X = df_train['text']\n",
        "y = df_train['target']\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Ys-_WFL7tL"
      },
      "source": [
        "#Linear reg\n",
        "LR = LogisticRegression(solver=\"lbfgs\", max_iter=100)\n",
        "\n",
        "#pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', LR)])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRVjRHl8MEWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70fe46b-9dff-43b1-a087-702f2113519d"
      },
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...,\n",
              "                                 tokenizer=<function spacy_tokenizer at 0x7ff76485d1e0>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkaJup57POCU"
      },
      "source": [
        "####Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p1LnofbPKVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9402693-31e2-4805-8d2c-f5ae69736898"
      },
      "source": [
        "#Accuracy of the train data\n",
        "y_pred_train = pipe.predict(X_train)\n",
        "print(f\"TRAIN ACCURACY SCORE:\\n{accuracy_score(y_train, y_pred_train):.4f}\")\n",
        "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_pred_train)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN ACCURACY SCORE:\n",
            "0.8924\n",
            "CONFUSION MATRIX:\n",
            "[[2873   88]\n",
            " [ 469 1746]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuqMFRCtIOdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bae5cf3-f4b6-4b9f-ef18-4d48773054a7"
      },
      "source": [
        "#Accuracy of the test data\n",
        "y_pred_test = pipe.predict(X_test)\n",
        "print(f\"TEST ACCURACY SCORE:\\n{accuracy_score(y_test, y_pred_test):.4f}\")\n",
        "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_pred_test)}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST ACCURACY SCORE:\n",
            "0.7861\n",
            "CONFUSION MATRIX:\n",
            "[[653  87]\n",
            " [190 365]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLiBgJB_Rsg3"
      },
      "source": [
        "####Using keywords only\n",
        "This is a test to see if using only the keywords would give a good accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EmmQH-AFcBC"
      },
      "source": [
        "#Replace null value by an arbitrary string\n",
        "df_train.keyword.fillna(value = 'nokeyword', inplace = True)\n",
        "\n",
        "#Verify\n",
        "df_train.keyword.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8EzaA20Savc"
      },
      "source": [
        "#Using keyword in the model\n",
        "features = ['keyword', 'text']\n",
        "\n",
        "X = df_train['keyword']\n",
        "y = df_train['target']\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXph3lkWSpAt"
      },
      "source": [
        "#Linear reg\n",
        "LR = LogisticRegression(solver=\"lbfgs\", max_iter=100)\n",
        "\n",
        "#pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', LR)])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0CScxfjfMmK",
        "outputId": "3570b36d-ba39-4488-cd72-2054355e182e"
      },
      "source": [
        "#Fit\n",
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...,\n",
              "                                 tokenizer=<function spacy_tokenizer at 0x7f0317681950>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EZ8O3oWxSwB",
        "outputId": "7e6f0793-c876-4423-891f-fd996d10f574"
      },
      "source": [
        "#Accuracy of the train data\n",
        "y_pred_train = pipe.predict(X_train)\n",
        "print(f\"TRAIN ACCURACY SCORE:\\n{accuracy_score(y_train, y_pred_train):.4f}\")\n",
        "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_pred_train)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN ACCURACY SCORE:\n",
            "0.7407\n",
            "CONFUSION MATRIX:\n",
            "[[2339  588]\n",
            " [ 737 1445]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tID-6k-Hb9u"
      },
      "source": [
        "#Data cleaning\n",
        "To further improve the accuracy of our model, we cleaned the text column by removing unecessary elements such as URL, Tags and noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odx5JWnMCWz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a91cce5-c848-425d-bd08-bb18e44a6531"
      },
      "source": [
        "#Clean duplicates\n",
        "df_train = df_train.drop_duplicates(subset=['text'], keep='first')\n",
        "df_train = df_train.dropna()\n",
        "\n",
        "\n",
        "#removing twitter tags\n",
        "def remove_tags(text):\n",
        "  text = re.sub(r'@\\S+',' ',text)\n",
        "  return text\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(lambda x: remove_tags(x))\n",
        "\n",
        "#replacing \"%20\" with space\n",
        "df_train['keyword'] = df_train['keyword'].replace('%20', ' ', regex = True)\n",
        "df_train['text'] = df_train['text'].replace('%20', ' ', regex = True)\n",
        "\n",
        "#removing url\n",
        "def remove_url(text):\n",
        "  text = re.sub(r'http\\S+', ' ', text)\n",
        "  return text\n",
        "  \n",
        "df_train['text'] = df_train['text'].apply(lambda x: remove_url(x))\n",
        "\n",
        "#removing punctuation and numbers and special letters\n",
        "def remove_punct(text):\n",
        "  text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "  text = re.sub('[0-9]+', '', text)\n",
        "  return text\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "#removing noises & special characters\n",
        "def remove_noise(text):\n",
        "  text = re.sub('RT', ' ', text)\n",
        "  text = re.sub('rT', ' ', text)\n",
        "  text = re.sub('Rt', ' ', text)\n",
        "  text = re.sub('rt', ' ', text)\n",
        "  text = re.sub('IB', ' ', text)\n",
        "  text = re.sub('\\n', ' ', text)\n",
        "  text = re.sub('¬â√ª¬™', ' ', text)\n",
        "  text = re.sub('¬â√•√™', ' ', text)\n",
        "  text = re.sub('¬â√•√ä', ' ', text)\n",
        "  text = re.sub('¬â¬©', ' ', text)\n",
        "  text = re.sub('¬â√ª', '', text)\n",
        "  text = re.sub(' +', ' ', text)\n",
        "  return text\n",
        "  \n",
        "df_train['text'] = df_train['text'].apply(lambda x: remove_noise(x))\n",
        "\n",
        "\n",
        "df_train['text'] = df_train['text'].str.lower()\n",
        "df_train['text'].str.strip()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       black eye a space battle occurred at star o in...\n",
              "2       reality training train falls off elevated trac...\n",
              "3       taiwan grace expect that large rocks trees mud...\n",
              "4       new isis video isis threatens to behead croati...\n",
              "5       freebesieged ma inmj yougov which tory landsli...\n",
              "                              ...                        \n",
              "6459    mt treatment of tigers in china is appalling e...\n",
              "6464    daily reflections august driven driven by a hu...\n",
              "6465    chinas stock market crash are there gems in th...\n",
              "6466    ea hquake sismo m km e of anchorage alaska tim...\n",
              "6469    friendly reminder that the only country to eve...\n",
              "Name: text, Length: 4281, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMOW2llDN2h9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b188a054-aa5b-46b9-d82f-addb8ecb38ce"
      },
      "source": [
        "#removing twitter tags\n",
        "def remove_tags(text):\n",
        "  text = re.sub(r'@\\S+',' ',text)\n",
        "  return text\n",
        "df_test['text'] = df_test['text'].apply(lambda x: remove_tags(x))\n",
        "\n",
        "#replacing \"%20\" with space\n",
        "df_test['keyword'] = df_test['keyword'].replace('%20', ' ', regex = True)\n",
        "df_test['text'] = df_test['text'].replace('%20', ' ', regex = True)\n",
        "\n",
        "#removing url\n",
        "def remove_url(text):\n",
        "  text = re.sub(r'http\\S+', ' ', text)\n",
        "  return text\n",
        "df_test['text'] = df_test['text'].apply(lambda x: remove_url(x))\n",
        "\n",
        "#removing punctuation\n",
        "def remove_punct(text):\n",
        "  text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "  text = re.sub('[0-9]+', '', text)\n",
        "  return text\n",
        "df_test['text'] = df_test['text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "#removing noises\n",
        "def remove_noise(text):\n",
        "  text = re.sub('RT', ' ', text)\n",
        "  text = re.sub('rT', ' ', text)\n",
        "  text = re.sub('Rt', ' ', text)\n",
        "  text = re.sub('rt', ' ', text)\n",
        "  text = re.sub('IB', ' ', text)\n",
        "  text = re.sub('\\n', ' ', text)\n",
        "  text = re.sub('¬â√ª¬™', ' ', text)\n",
        "  text = re.sub('¬â√•√™', ' ', text)\n",
        "  text = re.sub('¬â√•√ä', ' ', text)\n",
        "  text = re.sub('¬â¬©', ' ', text)\n",
        "  text = re.sub('¬â√ª', '', text)\n",
        "  text = re.sub(' +', ' ', text)\n",
        "  return text\n",
        "df_test['text'] = df_test['text'].apply(lambda x: remove_noise(x))\n",
        "\n",
        "df_test['text'] = df_test['text'].str.lower()\n",
        "df_test['text'].str.rstrip()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       crptotech tsunami and banks banking tech bitco...\n",
              "1       im that traumatised that i cant even spell pro...\n",
              "2        so where are the rioters looters and burning ...\n",
              "3                       me watching law amp order vine by\n",
              "4                       papi absolutely crushed that ball\n",
              "                              ...                        \n",
              "1137     im at work its a bunch of ppl and buses becau...\n",
              "1138     suicide bomber kills in saudi security site m...\n",
              "1139    eruption of indonesian volcano sparks transpo ...\n",
              "1140    never let fear get in the way of achieving you...\n",
              "1141     wowo nigerian refugees repatriated from cameroon\n",
              "Name: text, Length: 1142, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDbV_klpaMtr"
      },
      "source": [
        "#Using different classifiers\n",
        "\n",
        "We tried different classifier to know which one could predict the best our model\n",
        "\n",
        "##Logistic regression with cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esE7sSgDD0W-"
      },
      "source": [
        "#Setting up the train test split\n",
        "\n",
        "#First for the training data\n",
        "X = df_train['text']\n",
        "y = df_train['target']\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_f-4J4Ec3-Z"
      },
      "source": [
        "#Logistic regressin cross validation\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "LRCV = LRCV = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=123)\n",
        "#Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', LRCV)])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u_W7jCSxFuT",
        "outputId": "d5f6c460-c837-412c-9ea2-aee3cdf624d4"
      },
      "source": [
        "#Fit\n",
        "pipe.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...\n",
              "                                 tokenizer=<function spacy_tokenizer at 0x7f0317681950>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegressionCV(Cs=10, class_weight=None, cv=5,\n",
              "                                      dual=False, fit_intercept=True,\n",
              "                                      intercept_scaling=1.0, l1_ratios=None,\n",
              "                                      max_iter=1000, multi_class='auto',\n",
              "                                      n_jobs=None, penalty='l2',\n",
              "                                      random_state=123, refit=True,\n",
              "                                      scoring=None, solver='lbfgs', tol=0.0001,\n",
              "                                      verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyiGzPk7xHKx",
        "outputId": "c1dbe087-dd18-4080-d880-691f403de1ad"
      },
      "source": [
        "#Accuracy of the train data\n",
        "y_pred_train = pipe.predict(X_train)\n",
        "print(f\"TRAIN ACCURACY SCORE:\\n{accuracy_score(y_train, y_pred_train):.4f}\")\n",
        "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_pred_train)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN ACCURACY SCORE:\n",
            "0.9313\n",
            "CONFUSION MATRIX:\n",
            "[[2856   71]\n",
            " [ 280 1902]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI2EZnmQEfKV",
        "outputId": "95b0600c-5d19-48e3-ed77-f695e7880b6c"
      },
      "source": [
        "#Accuracy of the test data\n",
        "y_pred_test = pipe.predict(X_test)\n",
        "print(f\"TEST ACCURACY SCORE:\\n{accuracy_score(y_test, y_pred_test):.4f}\")\n",
        "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_pred_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST ACCURACY SCORE:\n",
            "0.7825\n",
            "CONFUSION MATRIX:\n",
            "[[645 104]\n",
            " [174 355]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vD9wEX2Igze",
        "outputId": "9d7c4284-96f4-44ff-cef2-578a8b8603d1"
      },
      "source": [
        "target_test = pipe.predict(df_test['text'])\n",
        "target_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz8uqYQqIhfP"
      },
      "source": [
        "sample_submission.target = target_test\n",
        "sample_submission.to_csv('submission-2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxIlB9TLtoQG"
      },
      "source": [
        "##Random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSo9mpXdvwUv"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "petfEC5-Mblp"
      },
      "source": [
        "#Setting up the train test split\n",
        "\n",
        "#First for the training data\n",
        "X = df_train['text']\n",
        "y = df_train['target']\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8kaQNLzwu3n"
      },
      "source": [
        "#Define classifier\n",
        "RFC = RandomForestClassifier(n_estimators = 10)\n",
        "#Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', RFC)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAtRRzNCxYYw",
        "outputId": "01a4b41d-1578-4121-d157-61b6fce752cb"
      },
      "source": [
        "#Fit\n",
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_patt...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=10, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbiQfd8kxeV0",
        "outputId": "e320e9f0-f318-4a50-b22a-07d05d707745"
      },
      "source": [
        "#Accuracy of the train data\n",
        "y_pred_train = pipe.predict(X_train)\n",
        "print(f\"TRAIN ACCURACY SCORE:\\n{accuracy_score(y_train, y_pred_train):.4f}\")\n",
        "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_pred_train)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN ACCURACY SCORE:\n",
            "0.9728\n",
            "CONFUSION MATRIX:\n",
            "[[2904   23]\n",
            " [ 116 2066]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkhvhW1OLpKv",
        "outputId": "abecf920-1df0-40d3-e92d-f262362c4ce1"
      },
      "source": [
        "#Accuracy of the test data\n",
        "y_pred_test = pipe.predict(X_test)\n",
        "print(f\"TEST ACCURACY SCORE:\\n{accuracy_score(y_test, y_pred_test):.4f}\")\n",
        "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_pred_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST ACCURACY SCORE:\n",
            "0.7621\n",
            "CONFUSION MATRIX:\n",
            "[[655  94]\n",
            " [210 319]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VPRXs6gJ3aI",
        "outputId": "227b0c51-b188-4e3c-d6f6-1b0119ee48da"
      },
      "source": [
        "target_test = pipe.predict(df_test['text'])\n",
        "target_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKGv4yYUJ4hX"
      },
      "source": [
        "sample_submission.target = target_test\n",
        "sample_submission.to_csv('submission-4.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN9rDmPBesOI"
      },
      "source": [
        "##Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "icDUVRUSzJvK",
        "outputId": "dacdad64-72c0-4631-c58d-a34f9010685e"
      },
      "source": [
        "text = df_train['text']\n",
        "text.head(5)\n",
        "text.to_csv('text.csv')\n",
        "from google.colab import files\n",
        "files.download('text.csv')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3c0ec88b-53af-4a1e-81c5-40f96b3eb96c\", \"text.csv\", 363245)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no6g7zWQfQgL",
        "outputId": "c11b70cd-61cd-482f-9baa-08920a9f63ac"
      },
      "source": [
        "#Tokenize data\n",
        "sample_tagged = df_train.apply(lambda r: TaggedDocument(words=spacy_tokenizer(r['text']), tags=[r.target]), axis=1)\n",
        "print(sample_tagged.head(20))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     ([black, eye, space, battl, occur, star, o, in...\n",
            "2     ([realiti, train, train, fall, elev, track, wi...\n",
            "3     ([taiwan, grace, expect, larg, rock, tree, mud...\n",
            "4     ([new, isi, video, isi, threaten, behead, croa...\n",
            "5     ([freebesieg, ma, inmj, yougov, tori, landslid...\n",
            "6     ([billionair, plan, free, half, billion, dolla...\n",
            "7     ([old, testimoni, weapon, use, promot, conflic...\n",
            "8     ([ali, fli, plane, run, burn, build, soup, man...\n",
            "10              ([polic, monitor, jihadi, poland], [1])\n",
            "11    ([dad, panic, weight, loss, mean, need, hurri,...\n",
            "12    ([alleg, driver, kuwait, attack, join, daesh, ...\n",
            "13    ([video, fire, burn, apa, ment, build, blow, c...\n",
            "16    ([god, forbid, famili, know, answer, phone, ne...\n",
            "17    ([micom, summer, contrast, candi, color, bowkn...\n",
            "18    ([abc, news, polic, offic, wound, suspect, dea...\n",
            "19    ([reddit, new, content, polici, effect, horrib...\n",
            "22    ([usual, d, agre, chop, head, throw, gay, roof...\n",
            "23    ([fire, hazard, associ, instal, noncompli, ext...\n",
            "26    ([threealarm, fire, destroy, residenti, build,...\n",
            "27    ([new, nanotech, devic, abl, target, destroy, ...\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E15fquA2iURf"
      },
      "source": [
        "# Train test split - same split as before\n",
        "train_tagged, test_tagged = train_test_split(sample_tagged, test_size=0.2, random_state=72)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5LDY8iCii2X"
      },
      "source": [
        "#Define Doc2Vec and build vocabulary\n",
        "model_dbow = Doc2Vec(dm=0, vector_size=30, negative=6, hs=0, min_count=1, sample=0, workers=cores, epoch=300)\n",
        "model_dbow.build_vocab([x for x in train_tagged.values])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fimIn8wciuuq"
      },
      "source": [
        "#Train distributed Bag of Word model\n",
        "model_dbow.train(train_tagged, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "250Od-wzi76Y"
      },
      "source": [
        "# Select X and y\n",
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=100)) for doc in sents])\n",
        "    return targets, regressors\n",
        "\n",
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAdHOWBjjM0p",
        "outputId": "591451f6-b317-4b3b-a36a-252857e60f17"
      },
      "source": [
        "# Fit model on training set - same algorithm as before\n",
        "logreg = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "print(round(accuracy_score(y_test, y_pred), 4))\n",
        "print(f\"CONFUSION MATRIX Test:\\n{confusion_matrix(y_test, y_pred)}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.776\n",
            "CONFUSION MATRIX Test:\n",
            "[[419  66]\n",
            " [126 246]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bbX5B51AQQ4",
        "outputId": "c7aafead-08dc-4ddd-fb7f-d1150dd13017"
      },
      "source": [
        "y_pred_train = logreg.predict(X_train)\n",
        "print(f\"TRAIN ACCURACY SCORE:\\n{accuracy_score(y_train, y_pred_train):.4f}\")\n",
        "print(f\"CONFUSION MATRIX Train:\\n{confusion_matrix(y_train, y_pred_train)}\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN ACCURACY SCORE:\n",
            "0.9019\n",
            "CONFUSION MATRIX Train:\n",
            "[[1761   97]\n",
            " [ 215 1109]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1tmsWfkZEH0"
      },
      "source": [
        "##Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qadwsxWqY6n"
      },
      "source": [
        "def remove_stopwords(text):\n",
        "  text_n = \"\"\n",
        "  for word in text:\n",
        "    if word not in stop_words:\n",
        "      \n",
        "      text_n = text_n + word\n",
        "  return text_n\n",
        "\n",
        "df_test['text'] = df_test['text'].apply(lambda x: remove_stopwords(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8ZDFQ-wvJQm"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIJU8HTuZM5k",
        "outputId": "e185b023-8e27-453c-c520-94632c5822ff"
      },
      "source": [
        "count = CountVectorizer(ngram_range=(1,2),stop_words=\"english\")\n",
        "bow = count.fit_transform(df_train['text'])\n",
        "bow.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "7GboslnKmlMu",
        "outputId": "8ab29469-5519-4429-afd6-c096273248b5"
      },
      "source": [
        "bow_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>aa batteries</th>\n",
              "      <th>aa near</th>\n",
              "      <th>aaaa</th>\n",
              "      <th>aaaa ok</th>\n",
              "      <th>aaaaaaallll</th>\n",
              "      <th>aaaaaaallll √ª¬™m</th>\n",
              "      <th>aaaaaand</th>\n",
              "      <th>aaaaaand theres</th>\n",
              "      <th>aaarrrgghhh</th>\n",
              "      <th>aal</th>\n",
              "      <th>aampb</th>\n",
              "      <th>aampb pipeliners</th>\n",
              "      <th>aampw</th>\n",
              "      <th>aampw pmclose</th>\n",
              "      <th>aan</th>\n",
              "      <th>aan den</th>\n",
              "      <th>aannnnd</th>\n",
              "      <th>aannnnd reddit</th>\n",
              "      <th>aar</th>\n",
              "      <th>aar ambulancewe</th>\n",
              "      <th>aashiqui</th>\n",
              "      <th>aashiqui actress</th>\n",
              "      <th>ab</th>\n",
              "      <th>ab resin</th>\n",
              "      <th>aba</th>\n",
              "      <th>aba woman</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abandon plans</th>\n",
              "      <th>abandon west</th>\n",
              "      <th>abandoned</th>\n",
              "      <th>abandoned aircraft</th>\n",
              "      <th>abandoned cabin</th>\n",
              "      <th>abandoned cocker</th>\n",
              "      <th>abandoned station</th>\n",
              "      <th>abandoning</th>\n",
              "      <th>abandoning deal</th>\n",
              "      <th>abbandoned</th>\n",
              "      <th>abbandoned sinking</th>\n",
              "      <th>abbott</th>\n",
              "      <th>...</th>\n",
              "      <th>√ª√≤ lovefood</th>\n",
              "      <th>√ª√≤ malaysian</th>\n",
              "      <th>√ª√≤ musicians</th>\n",
              "      <th>√ª√≤ news</th>\n",
              "      <th>√ª√≤ pa</th>\n",
              "      <th>√ª√≤ public</th>\n",
              "      <th>√ª√≤ residents</th>\n",
              "      <th>√ª√≤ sky√•√™news</th>\n",
              "      <th>√ª√≤ steve</th>\n",
              "      <th>√ª√≤ usa</th>\n",
              "      <th>√ª√≤ video</th>\n",
              "      <th>√ª√≤ vladimir</th>\n",
              "      <th>√ª√≤ √ª√Ødetonate</th>\n",
              "      <th>√ª√≤the</th>\n",
              "      <th>√ª√≤the united</th>\n",
              "      <th>√ª√≤√•√™cnbc</th>\n",
              "      <th>√ª√≥</th>\n",
              "      <th>√ª√≥ athlete</th>\n",
              "      <th>√ª√≥ britain</th>\n",
              "      <th>√ª√≥ bulletproof</th>\n",
              "      <th>√ª√≥ eh</th>\n",
              "      <th>√ª√≥ head</th>\n",
              "      <th>√ª√≥ hiroshimanagasaki</th>\n",
              "      <th>√ª√≥ integrates</th>\n",
              "      <th>√ª√≥ lol</th>\n",
              "      <th>√ª√≥ news</th>\n",
              "      <th>√ª√≥ officials</th>\n",
              "      <th>√ª√≥ oh</th>\n",
              "      <th>√ª√≥ organizers</th>\n",
              "      <th>√ª√≥ richmond</th>\n",
              "      <th>√ª√≥ stories</th>\n",
              "      <th>√ª√≥ √ª¬™m</th>\n",
              "      <th>√ª√≥bbc</th>\n",
              "      <th>√ª√≥bbc looks</th>\n",
              "      <th>√ª√≥her</th>\n",
              "      <th>√ª√≥her upper</th>\n",
              "      <th>√ª√≥kody</th>\n",
              "      <th>√ª√≥kody vine</th>\n",
              "      <th>√ª√≥negligence</th>\n",
              "      <th>√ª√≥negligence fireworks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5893</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5894</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5895</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5896</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5897</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5898 rows √ó 48424 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      aa  aa batteries  ...  √ª√≥negligence  √ª√≥negligence fireworks\n",
              "0      0             0  ...             0                       0\n",
              "1      0             0  ...             0                       0\n",
              "2      0             0  ...             0                       0\n",
              "3      0             0  ...             0                       0\n",
              "4      0             0  ...             0                       0\n",
              "...   ..           ...  ...           ...                     ...\n",
              "5893   0             0  ...             0                       0\n",
              "5894   0             0  ...             0                       0\n",
              "5895   0             0  ...             0                       0\n",
              "5896   0             0  ...             0                       0\n",
              "5897   0             0  ...             0                       0\n",
              "\n",
              "[5898 rows x 48424 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQxubR10T8oJ"
      },
      "source": [
        "##Submission üëÄ\n",
        "This is the code that we use to create the submission. To use it, we can just copy/paste it below the classifier of our choice and rename the .csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCEjC8RQ2WEa"
      },
      "source": [
        "df_test['target'] = np.zeros"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCeKynLTkyDs",
        "outputId": "b642f7b2-82ff-4847-a59d-02c0ce336fc4"
      },
      "source": [
        "sample_tagged = df_test.apply(lambda r: TaggedDocument(words=spacy_tokenizer(r['text']), tags=[r.target]), axis=1)\n",
        "print(sample_tagged.head(20))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1     ([traumatis, spell, properli, excus, typo], [<...\n",
            "4     ([papi, absolut, crush, ball], [<built-in func...\n",
            "6     ([twitsandiego, possibl, sinkhol, disrupt, tro...\n",
            "8     ([kessler, syndrom, catastroph, exponenti, pro...\n",
            "9     ([train, derail, instead, work, earli, like, l...\n",
            "10    ([new, evacu, order, home, danger, hwi, fire, ...\n",
            "11    ([bbcnew, ass, british, insur, riot, cost, ins...\n",
            "13    ([littl, piec, write, avalanch, design, blog, ...\n",
            "15    ([let, s, talk, goof, guild, saunder, come, ri...\n",
            "16    ([kelbi, tomlinson, mildmanner, nd, baseman, g...\n",
            "17    ([join, chariti, k, run, event, sta, sun, sept...\n",
            "19    ([ahh, forget, headphon, suppos, surviv, day, ...\n",
            "20    ([uncl, wreck, shit], [<built-in function zero...\n",
            "21    ([eu, state, squabbl, immigr, ukfranc, eurotun...\n",
            "22    ([japan, resta, nuclear, reactor, fleet, fast,...\n",
            "24    ([total, agre, rape, kill, destroy, leav, land...\n",
            "25    ([fire, pisgah, nation, forest, grow, acr], [<...\n",
            "26    ([s, fire, alarm, zehr, work, minut, decid, ev...\n",
            "28    ([mh, intact, pa, lift, odd, plane, glide, cra...\n",
            "29    ([countri, latin, america, argentina, week, ag...\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J89o5oJlD64"
      },
      "source": [
        "\n",
        "y_target, X_target = vec_for_learning(model_dbow, sample_tagged)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbciTNBET70C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bce1d01-d877-4849-eaff-2d9d39e49b20"
      },
      "source": [
        "target_test = logreg.predict(X_target)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "qGWWBRuU5Jcn",
        "outputId": "3b7700d3-e265-4ec2-da77-49cabc2266dc"
      },
      "source": [
        "sample_submission['target'] = target_test\n",
        "sample_submission.head(5)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-d3d2e2698c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3767\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         raise ValueError(\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (742) does not match length of index (1142)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OvzdksGVZST"
      },
      "source": [
        "\n",
        "sample_submission['target'].to_csv('submission-11.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "khkoj5Tz21qW",
        "outputId": "47b338fb-4e52-4116-ca96-1a72121f2813"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submission-11.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_62b6787e-c4b6-4b32-aa3c-18fb832b20d7\", \"submission-11.csv\", 2291)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}